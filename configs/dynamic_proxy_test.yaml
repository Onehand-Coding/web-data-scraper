name: "Dynamic Scraper Proxy Test"
description: "Test dynamic scraping (Selenium) with proxy rotation using quotes.toscrape.com/js"
urls:
  # Using the JS version of quotes.toscrape requires dynamic scraping
  - "https://quotes.toscrape.com/js/"
dynamic: true # <-- IMPORTANT: Set to true for DynamicScraper

# --- Dynamic Options ---
# Wait for the main content area or a specific quote element to appear
wait_for_selector: "div.quote"
# Give JS time to load, adjust as needed
wait_time: 5
# Set headless to false if you want to watch the browser (useful for debugging)
headless: true
# page_load_timeout: 30 # Keep default or adjust

selectors:
  type: css
  # container: "div.quotes" # Optional container for JS version
  item: "div.quote"
  fields:
    quote_text: "span.text"
    author: "small.author"
    tags_raw: "div.tags" # Keep raw tags for processing

# --- Pagination (Example for JS site, might need adjustment) ---
pagination:
  # The JS site loads more quotes on the same page, doesn't use traditional next link.
  # Pagination via click might not work directly here.
  # For testing proxy rotation, limit pages or remove pagination.
  max_pages: 2 # Limit pages to test proxy rotation across loads if applicable

# --- Proxy Configuration ---
# Corrected indentation for the proxies list:
proxies:
  # Option 1: Test WITHOUT proxies (leave list empty or comment out)
  # []

  # Option 2: Test WITH dummy/invalid proxies (to check error handling)
  # - http: 'http://127.0.0.1:1'
  #   https: 'http://127.0.0.1:1'
  # - http: 'http://nonexistentproxy.local:8888'
  #   https: 'http://nonexistentproxy.local:8888'

  # Option 3: Test WITH your actual proxies (REPLACE THESE - currently dummy)
  - http: 'http://user1:pass1@proxy.example.com:8080'
    https: 'http://user1:pass1@proxy.example.com:8080'
  - http: 'http://192.168.1.100:3128'
    https: 'http://192.168.1.100:3128'

# --- Processing Rules ---
processing_rules:
  text_cleaning:
    quote_text: {trim: true, regex_replace: {'^[“”"]': '', '[“”"]$': ''}}
    author: {trim: true}
  validations:
    quote_text: {required: true, min_length: 5}
    author: {required: true}
  transformations:
    tags: |
      ', '.join(tag.strip() for tag in value.replace('Tags:', '').split('\n') if tag.strip()) if isinstance(value, str) else ''
  drop_fields:
    - tags_raw

# --- Common Options ---
output_dir: "outputs/dynamic_proxy_test"
request_delay: 3 # Selenium actions inherently take time, but delay can still be useful
max_retries: 2   # Retries for base fetching, less relevant for Selenium page loads
user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36"
respect_robots: true # Still good practice, though checked via requests before Selenium starts
