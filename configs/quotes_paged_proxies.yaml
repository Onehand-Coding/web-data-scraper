name: Quotes Scraper Test - Paged with Proxies
description: Test scraping multiple pages with proxy rotation.
urls:
  - https://quotes.toscrape.com/ # Start URL
dynamic: false
selectors:
  type: css # Type is specified here now
  item: div.quote
  fields:
    quote_text: span.text
    author: small.author
    tags_raw: div.tags

# --- Pagination Rules ---
pagination:
  next_page_selector: li.next a # Selector for the 'Next →' link <a> tag
  max_pages: 3                 # Limit to scraping 3 pages total for testing

# --- Proxy Configuration ---
proxies: []
  # - http: 'http://user1:pass1@proxy.example.com:8080'  # Replace with your proxy details
  #   https: 'http://user1:pass1@proxy.example.com:8080' # Replace with your proxy details
  # - http: 'http://192.168.1.100:3128'                   # Example without authentication
  #   https: 'http://192.168.1.100:3128'                  # Example without authentication
  # Add more proxies following the same format
  # - http: 'http://another_proxy:port'
  #   https: 'http://another_proxy:port'

# --- Processing Rules ---
processing_rules:
  text_cleaning:
    quote_text: {trim: true, regex_replace: {'^[“”"]': '', '[“”"]$': ''}}
    author: {trim: true}
  validations:
    quote_text: {required: true, min_length: 5}
    author: {required: true}
  transformations:
    # Use YAML literal block style for better readability of the expression
    tags: |
      ', '.join(tag.strip() for tag in value.replace('Tags:', '').split('\n') if tag.strip()) if isinstance(value, str) else ''
  drop_fields:
    - tags_raw

output_dir: outputs/quotes_paged_proxies # Use a specific output dir
request_delay: 2 # Increased delay slightly, often needed with proxies
max_retries: 3   # Keep retries, useful if a proxy fails
user_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36
respect_robots: true
